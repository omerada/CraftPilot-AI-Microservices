server:
  port: 8062
  compression:
    enabled: true
    mime-types: application/json,text/plain
    min-response-size: 1024
  shutdown: graceful
  netty:
    connection-timeout: 5000
    idle-timeout: 30000
    max-keep-alive-requests: 1000
    threads:
      worker: 4
      boss: 1
    validate-headers: true
    max-connections: 10000
    max-initial-line-length: 8192
    max-header-size: 16384
  error:
    include-message: always
    include-binding-errors: always
    include-stacktrace: never
    include-exception: false

spring:
  application:
    name: llm-service
  profiles:
    active: ${SPRING_PROFILES_ACTIVE:dev}
    include: kafka-base
  main:
    web-application-type: reactive
    allow-bean-definition-overriding: true
  webflux:
    base-path: /
    format:
      date: yyyy-MM-dd
      date-time: yyyy-MM-dd HH:mm:ss
      time: HH:mm:ss
    log-request-details: true
  codec:
    max-in-memory-size: 16MB
    log-request-details: true
  kafka:
    properties:
      security.protocol: PLAINTEXT
      reconnect.backoff.ms: 1000
      reconnect.backoff.max.ms: 5000
    consumer:
      auto-offset-reset: earliest
      group-id: llm-service-group
    producer:
      retries: 3
      acks: all
  cloud:
    discovery:
      enabled: true
  data:
    redis:
      host: ${REDIS_HOST:redis}
      port: ${REDIS_PORT:6379}
      password: ${REDIS_PASSWORD:13579ada}
      timeout: 5000
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 2
          max-wait: 1000ms
  cache:
    type: redis
    redis:
      time-to-live: 3600000
      cache-null-values: false
      use-key-prefix: true
  reactor:
    netty:
      pool:
        type: elastic
        maxConnections: 500
        acquireTimeout: 5000
      client:
        proxy:
          type: NO_PROXY
  security:
    basic:
      enabled: false

eureka:
  client:
    serviceUrl:
      defaultZone: ${EUREKA_CLIENT_SERVICEURL_DEFAULTZONE:http://craftpilot:13579ada@eureka-server:8761/eureka/}
    register-with-eureka: true
    fetch-registry: true
  instance:
    prefer-ip-address: false
    hostname: ${HOSTNAME:llm-service}
    lease-renewal-interval-in-seconds: 10
    health-check-url-path: /actuator/health
    status-page-url-path: /actuator/info
    home-page-url: http://${eureka.instance.hostname}:${server.port}/

management:
  endpoints:
        include: health,info
      base-path: /actuator
        include: health,info
      base-path: /actuator
  endpoint:
      probes:
        enabled: truelways
      probes:
        enabled: true
      group:
    key: ${OPENROUTER_API_KEY}:
    url: https://openrouter.ai/api/v1
    defaultModel: google/gemini-2.0-flash-lite-preview-02-05:freeiveness:
    maxTokens: 2000 "*"
    temperature: 0.7
    retryAttempts: 3
    retryDelay: 1000
    http-referer: https://craftpilot.io    readinessstate:
ed: true
kafka:
  topics:
    ai-events: ai-events
    llm-completions: llm-completions
enrouter.ai/api/v1
logging:ogle/gemini-2.0-flash-lite-preview-02-05:free
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] [%X{traceId}] %-5level %logger{36} - %msg%n"
  level:
    root: INFO    retryDelay: 1000
    com.craftpilot: DEBUGtp-referer: https://craftpilot.io
    org.springframework.web: DEBUG
    org.springframework.cloud: DEBUG
    reactor.netty: DEBUG
    io.netty: DEBUG    ai-events: ai-events
    com.craftpilot.llmservice: DEBUGcompletions: llm-completions

netty:
  native:n:
    enabled: false%d{yyyy-MM-dd HH:mm:ss} [%thread] [%X{traceId}] %-5level %logger{36} - %msg%n"
  io:
    noNative: true
    noUnsafe: true
  use-native-transport: trueweb: DEBUG
  workdir: /tmp/nettywork.cloud: DEBUG

resilience4j:    io.netty: DEBUG
  circuitbreaker:m.craftpilot.llmservice: DEBUG
nces:
netty:
        slidingWindowSize: 100ive:
        failureRateThreshold: 50
        waitDurationInOpenState: 20s
        permittedNumberOfCallsInHalfOpenState: 10
  ratelimiter:
    instances:  use-native-transport: true
      llmService:mp/netty
        limitForPeriod: 100
        limitRefreshPeriod: 1s
        timeoutDuration: 5s
  bulkhead:
    instances:
      llmService:
        maxConcurrentCalls: 50
        permittedNumberOfCallsInHalfOpenState: 10  ratelimiter:    instances:      llmService:        limitForPeriod: 100        limitRefreshPeriod: 1s        timeoutDuration: 5s  bulkhead:    instances:      llmService:
        maxConcurrentCalls: 50
